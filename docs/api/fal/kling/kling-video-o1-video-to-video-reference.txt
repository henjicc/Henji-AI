# Kling O1 Reference Video to Video

> Kling O1 Omni generates new shots guided by an input reference video, preserving cinematic language such as motion, and camera style to produce seamless scene continuity.


## Overview

- **Endpoint**: `https://fal.run/fal-ai/kling-video/o1/video-to-video/reference`
- **Model ID**: `fal-ai/kling-video/o1/video-to-video/reference`
- **Category**: video-to-video
- **Kind**: inference


## API Information

This model can be used via our HTTP API or more conveniently via our client libraries.
See the input and output schema below, as well as the usage examples.


### Input Schema

The API accepts the following input parameters:


- **`prompt`** (`string`, _required_):
  Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.
  - Examples: "Based on @Video1, generate the next shot. keep the style of the video"

- **`video_url`** (`string`, _required_):
  Reference video URL. Only .mp4/.mov formats supported, 3-10 seconds duration, 720-2160px resolution, max 200MB.
  - Examples: "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4"

- **`keep_audio`** (`boolean`, _optional_):
  Whether to keep the original audio from the video.
  - Default: `false`

- **`image_urls`** (`list<string>`, _optional_):
  Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.
  - Array of string
  - Examples: []

- **`elements`** (`list<OmniVideoElementInput>`, _optional_):
  Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.
  - Array of OmniVideoElementInput
  - Examples: [{"reference_image_urls":["https://v3b.fal.media/files/b/zebra/YvRbjNmoauvqs0ltcXiXJ.png"],"frontal_image_url":"https://v3b.fal.media/files/b/rabbit/Jdn8H24frD9Cd31GiJuk3.png"}]

- **`aspect_ratio`** (`AspectRatioEnum`, _optional_):
  The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used. Default value: `"auto"`
  - Default: `"auto"`
  - Options: `"auto"`, `"16:9"`, `"9:16"`, `"1:1"`

- **`duration`** (`DurationEnum`, _optional_):
  Video duration in seconds. Default value: `"5"`
  - Default: `"5"`
  - Options: `"5"`, `"10"`



**Required Parameters Example**:

```json
{
  "prompt": "Based on @Video1, generate the next shot. keep the style of the video",
  "video_url": "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4"
}
```

**Full Example**:

```json
{
  "prompt": "Based on @Video1, generate the next shot. keep the style of the video",
  "video_url": "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4",
  "image_urls": [],
  "elements": [
    {
      "reference_image_urls": [
        "https://v3b.fal.media/files/b/zebra/YvRbjNmoauvqs0ltcXiXJ.png"
      ],
      "frontal_image_url": "https://v3b.fal.media/files/b/rabbit/Jdn8H24frD9Cd31GiJuk3.png"
    }
  ],
  "aspect_ratio": "auto",
  "duration": "5"
}
```


### Output Schema

The API returns the following output format:

- **`video`** (`File`, _required_):
  The generated video.
  - Examples: {"file_size":28472159,"file_name":"output.mp4","content_type":"video/mp4","url":"https://v3b.fal.media/files/b/kangaroo/3n_Lpxm_SjK5NYyBobRdS_output.mp4"}



**Example Response**:

```json
{
  "video": {
    "file_size": 28472159,
    "file_name": "output.mp4",
    "content_type": "video/mp4",
    "url": "https://v3b.fal.media/files/b/kangaroo/3n_Lpxm_SjK5NYyBobRdS_output.mp4"
  }
}
```


## Usage Examples

### cURL

```bash
curl --request POST \
  --url https://fal.run/fal-ai/kling-video/o1/video-to-video/reference \
  --header "Authorization: Key $FAL_KEY" \
  --header "Content-Type: application/json" \
  --data '{
     "prompt": "Based on @Video1, generate the next shot. keep the style of the video",
     "video_url": "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4"
   }'
```

### Python

Ensure you have the Python client installed:

```bash
pip install fal-client
```

Then use the API client to make requests:

```python
import fal_client

def on_queue_update(update):
    if isinstance(update, fal_client.InProgress):
        for log in update.logs:
           print(log["message"])

result = fal_client.subscribe(
    "fal-ai/kling-video/o1/video-to-video/reference",
    arguments={
        "prompt": "Based on @Video1, generate the next shot. keep the style of the video",
        "video_url": "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4"
    },
    with_logs=True,
    on_queue_update=on_queue_update,
)
print(result)
```

### JavaScript

Ensure you have the JavaScript client installed:

```bash
npm install --save @fal-ai/client
```

Then use the API client to make requests:

```javascript
import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/o1/video-to-video/reference", {
  input: {
    prompt: "Based on @Video1, generate the next shot. keep the style of the video",
    video_url: "https://v3b.fal.media/files/b/panda/oVdiICFXY03Vbam-08Aj8_output.mp4"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
```


## Additional Resources

### Documentation

- [Model Playground](https://fal.ai/models/fal-ai/kling-video/o1/video-to-video/reference)
- [API Documentation](https://fal.ai/models/fal-ai/kling-video/o1/video-to-video/reference/api)
- [OpenAPI Schema](https://fal.ai/api/openapi/queue/openapi.json?endpoint_id=fal-ai/kling-video/o1/video-to-video/reference)

### fal.ai Platform

- [Platform Documentation](https://docs.fal.ai)
- [Python Client](https://docs.fal.ai/clients/python)
- [JavaScript Client](https://docs.fal.ai/clients/javascript)
