# Vidu

> Use the latest Vidu Q2 models which much more better quality and control on your videos.


## Overview

- **Endpoint**: `https://fal.run/fal-ai/vidu/q2/image-to-video/turbo`
- **Model ID**: `fal-ai/vidu/q2/image-to-video/turbo`
- **Category**: image-to-video
- **Kind**: inference
**Tags**: image-to-video



## API Information

This model can be used via our HTTP API or more conveniently via our client libraries.
See the input and output schema below, as well as the usage examples.


### Input Schema

The API accepts the following input parameters:


- **`prompt`** (`string`, _required_):
  Text prompt for video generation, max 3000 characters
  - Examples: "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement."

- **`image_url`** (`string`, _required_):
  URL of the image to use as the starting frame
  - Examples: "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"

- **`seed`** (`integer`, _optional_):
  Random seed for reproducibility. If None, a random seed is chosen.

- **`duration`** (`DurationEnum`, _optional_):
  Duration of the video in seconds Default value: `"4"`
  - Default: `4`
  - Options: `2`, `3`, `4`, `5`, `6`, `7`, `8`

- **`resolution`** (`ResolutionEnum`, _optional_):
  Output video resolution Default value: `"720p"`
  - Default: `"720p"`
  - Options: `"720p"`, `"1080p"`

- **`movement_amplitude`** (`MovementAmplitudeEnum`, _optional_):
  The movement amplitude of objects in the frame Default value: `"auto"`
  - Default: `"auto"`
  - Options: `"auto"`, `"small"`, `"medium"`, `"large"`

- **`bgm`** (`boolean`, _optional_):
  Whether to add background music to the video (only for 4-second videos)
  - Default: `false`



**Required Parameters Example**:

```json
{
  "prompt": "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement.",
  "image_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
}
```

**Full Example**:

```json
{
  "prompt": "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement.",
  "image_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp",
  "duration": 4,
  "resolution": "720p",
  "movement_amplitude": "auto"
}
```


### Output Schema

The API returns the following output format:

- **`video`** (`File`, _required_):
  The generated video from image using the Q2 model
  - Examples: {"url":"https://fal.media/files/tiger/L_lU76tYg-cXG_twy9N62_output.mp4"}



**Example Response**:

```json
{
  "video": {
    "url": "https://fal.media/files/tiger/L_lU76tYg-cXG_twy9N62_output.mp4"
  }
}
```


## Usage Examples

### cURL

```bash
curl --request POST \
  --url https://fal.run/fal-ai/vidu/q2/image-to-video/turbo \
  --header "Authorization: Key $FAL_KEY" \
  --header "Content-Type: application/json" \
  --data '{
     "prompt": "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement.",
     "image_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
   }'
```

### Python

Ensure you have the Python client installed:

```bash
pip install fal-client
```

Then use the API client to make requests:

```python
import fal_client

def on_queue_update(update):
    if isinstance(update, fal_client.InProgress):
        for log in update.logs:
           print(log["message"])

result = fal_client.subscribe(
    "fal-ai/vidu/q2/image-to-video/turbo",
    arguments={
        "prompt": "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement.",
        "image_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
    },
    with_logs=True,
    on_queue_update=on_queue_update,
)
print(result)
```

### JavaScript

Ensure you have the JavaScript client installed:

```bash
npm install --save @fal-ai/client
```

Then use the API client to make requests:

```javascript
import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/vidu/q2/image-to-video/turbo", {
  input: {
    prompt: "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement.",
    image_url: "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
```


## Additional Resources

### Documentation

- [Model Playground](https://fal.ai/models/fal-ai/vidu/q2/image-to-video/turbo)
- [API Documentation](https://fal.ai/models/fal-ai/vidu/q2/image-to-video/turbo/api)
- [OpenAPI Schema](https://fal.ai/api/openapi/queue/openapi.json?endpoint_id=fal-ai/vidu/q2/image-to-video/turbo)

### fal.ai Platform

- [Platform Documentation](https://docs.fal.ai)
- [Python Client](https://docs.fal.ai/clients/python)
- [JavaScript Client](https://docs.fal.ai/clients/javascript)
